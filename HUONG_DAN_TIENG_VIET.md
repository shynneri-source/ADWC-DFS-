# HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng ADWC-DFS (Tiáº¿ng Viá»‡t)

## ğŸ¯ Giá»›i Thiá»‡u

**ADWC-DFS** (Adaptive Density-Weighted Cascade with Dynamic Feature Synthesis) lÃ  má»™t thuáº­t toÃ¡n machine learning tiÃªn tiáº¿n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho bÃ i toÃ¡n **phÃ¡t hiá»‡n gian láº­n** vá»›i dá»¯ liá»‡u máº¥t cÃ¢n báº±ng.

### Äáº·c Ä‘iá»ƒm ná»•i báº­t:
- âœ… KhÃ´ng cáº§n resampling (SMOTE, oversampling)
- âœ… Nhanh vÃ  hiá»‡u quáº£ (O(nÂ·kÂ·d))
- âœ… Dá»… hiá»ƒu vÃ  giáº£i thÃ­ch Ä‘Æ°á»£c
- âœ… Sáºµn sÃ ng triá»ƒn khai production
- âœ… Ãt hyperparameter cáº§n tune

## ğŸ—ï¸ Kiáº¿n TrÃºc

Thuáº­t toÃ¡n gá»“m 4 giai Ä‘oáº¡n:

### Giai Ä‘oáº¡n 1: PhÃ¢n TÃ­ch Máº­t Äá»™ Cá»¥c Bá»™
TÃ­nh toÃ¡n Ä‘á»™ khÃ³ cho má»—i máº«u dá»±a trÃªn:
- **LID**: Äá»™ phá»©c táº¡p khÃ´ng gian cá»¥c bá»™
- **CCDR**: Tá»· lá»‡ máº­t Ä‘á»™ giá»¯a cÃ¡c class
- **DS**: Äiá»ƒm sá»‘ Ä‘á»™ khÃ³ tá»•ng há»£p

### Giai Ä‘oáº¡n 2: Huáº¥n Luyá»‡n Cascade
Ba mÃ´ hÃ¬nh chuyÃªn biá»‡t:
- **Easy Model**: Há»c cÃ¡c máº«u dá»…
- **Medium Model**: Há»c táº¥t cáº£ máº«u
- **Hard Model**: Táº­p trung vÃ o máº«u khÃ³

### Giai Ä‘oáº¡n 3: Tá»•ng Há»£p Äáº·c TrÆ°ng Äá»™ng
Táº¡o meta-features tá»«:
- Sá»± báº¥t Ä‘á»“ng giá»¯a cÃ¡c models
- Äá»™ tin cáº­y cá»§a predictions
- Äá»“ng thuáº­n tá»« neighbors

### Giai Ä‘oáº¡n 4: Meta-Classifier
MÃ´ hÃ¬nh cuá»‘i cÃ¹ng vá»›i:
- Adaptive weighting
- Uncertainty-based learning

## ğŸ“¦ CÃ i Äáº·t

```bash
# Di chuyá»ƒn vÃ o thÆ° má»¥c project
cd /home/shynn/source/ADWC-DFS

# CÃ i Ä‘áº·t dependencies vá»›i UV (khuyáº¿n nghá»‹)
uv sync

# Hoáº·c dÃ¹ng pip
pip install -r requirements.txt
```

## ğŸš€ Sá»­ Dá»¥ng Nhanh

### 1. Cháº¡y Demo (Khuyáº¿n nghá»‹ báº¯t Ä‘áº§u)

```bash
uv run demo.py
```

Demo sáº½:
- Load 10% dá»¯ liá»‡u training
- Huáº¥n luyá»‡n model ADWC-DFS
- ÄÃ¡nh giÃ¡ performance
- Hiá»ƒn thá»‹ feature importance
- Show cÃ¡c predictions máº«u

**Thá»i gian cháº¡y:** ~2-3 phÃºt

### 2. Training Äáº§y Äá»§

```bash
# Train vá»›i toÃ n bá»™ dá»¯ liá»‡u
uv run train.py --train_path data/train.csv --test_path data/test.csv
# ğŸ“ Log tá»± Ä‘á»™ng: logs/training_YYYYMMDD_HHMMSS.log

# Test nhanh vá»›i 10% dá»¯ liá»‡u
uv run train.py --sample_frac 0.1

# TÃ¹y chá»‰nh cáº¥u hÃ¬nh
uv run train.py --k_neighbors 50 --output_dir experiments/run1

# Training khÃ´ng lÆ°u log (náº¿u muá»‘n nhanh hÆ¡n)
uv run train.py --no_log
```

**Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u vÃ o:**
- `results/adwc_dfs_model.pkl` - Model Ä‘Ã£ train
- `results/metrics.csv` - Metrics Ä‘Ã¡nh giÃ¡
- `results/feature_importance.csv` - Äá»™ quan trá»ng features
- `results/plots/` - CÃ¡c biá»ƒu Ä‘á»“
- `logs/training_*.log` - **Log Ä‘áº§y Ä‘á»§ quÃ¡ trÃ¬nh training** ğŸ“

### 2.5. Training Ensemble (NÃ¢ng cao Recall) â­

```bash
# Test nhanh ensemble vá»›i 10% data (~5-10 phÃºt)
python test_ensemble.py

# Train ensemble Ä‘áº§y Ä‘á»§ vá»›i 5 models (~30-60 phÃºt)
python ensemble_voting.py --n_models 5

# Test vá»›i 10% data
python ensemble_voting.py --n_models 5 --sample_frac 0.1

# Aggressive vá»›i 7 models
python ensemble_voting.py --n_models 7
```

**Káº¿t quáº£ Ensemble:**
- `results/ensemble_model.pkl` - Ensemble Ä‘Ã£ train
- `results/ensemble_results.csv` - Performance metrics
- Recall: **90%+** (cáº£i thiá»‡n tá»« 87%)

**ğŸ“š Xem chi tiáº¿t:** [ENSEMBLE_USAGE_GUIDE.md](ENSEMBLE_USAGE_GUIDE.md)

### 3. So SÃ¡nh Vá»›i Baselines

```bash
uv run evaluate.py --sample_frac 0.1 --output_csv results/comparison.csv
# ğŸ“ Log: logs/evaluation_YYYYMMDD_HHMMSS.log
```

So sÃ¡nh vá»›i:
- XGBoost vá»›i class weights
- SMOTE + XGBoost  
- Random Forest
- ADWC-DFS

## ğŸ“ Xem Training Logs

**Táº¥t cáº£ training tá»± Ä‘á»™ng lÆ°u log!**

```bash
# Liá»‡t kÃª táº¥t cáº£ logs
uv run view_logs.py --list

# Xem log má»›i nháº¥t
uv run view_logs.py --latest

# Xem log cá»¥ thá»ƒ (sá»‘ thá»© tá»± tá»« list)
uv run view_logs.py --view 1

# TÃ¬m kiáº¿m trong logs
uv run view_logs.py --search "F1 Score"

# Xem 100 dÃ²ng cuá»‘i
uv run view_logs.py --latest --lines 100 --tail

# Chá»‰ xem training logs
uv run view_logs.py --list --prefix training
```

**Log files:** `logs/training_YYYYMMDD_HHMMSS.log`

**Xem chi tiáº¿t:** [LOGGING_GUIDE.md](LOGGING_GUIDE.md) - HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ vá» logging

## ğŸ’» Sá»­ Dá»¥ng Trong Code

### CÃ¡ch 1: CÆ¡ Báº£n (Single Model)

```python
from adwc_dfs import ADWCDFS

# Khá»Ÿi táº¡o model vá»›i config máº·c Ä‘á»‹nh
model = ADWCDFS(verbose=1)

# Huáº¥n luyá»‡n
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred_proba = model.predict_proba(X_test)
y_pred = model.predict(X_test, threshold=0.5)

# Feature importance
importance = model.get_feature_importance()
print(importance.head(10))
```

### CÃ¡ch 1.5: Ensemble (Recall cao hÆ¡n) â­

```python
from ensemble_voting import VotingEnsemble

# Táº¡o ensemble vá»›i 5 models
ensemble = VotingEnsemble(n_models=5, voting='soft', verbose=1)

# Huáº¥n luyá»‡n
ensemble.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n vá»›i soft voting (cÃ¢n báº±ng)
y_pred = ensemble.predict(X_test, threshold=0.13)

# Hoáº·c aggressive voting (maximize recall)
y_pred = ensemble.predict_aggressive(X_test, min_votes=2)

# Save ensemble
ensemble.save('results/ensemble_model.pkl')

# Load vÃ  sá»­ dá»¥ng
loaded = VotingEnsemble.load('results/ensemble_model.pkl')
```

### CÃ¡ch 2: TÃ¹y Chá»‰nh Config

```python
from adwc_dfs import ADWCDFS
from adwc_dfs.config import ADWCDFSConfig

# Táº¡o config tÃ¹y chá»‰nh
config = ADWCDFSConfig()
config.K_NEIGHBORS = 50           # TÄƒng sá»‘ neighbors
config.ALPHA = 0.5                # TÄƒng trá»ng sá»‘ CCDR
config.SCALE_POS_WEIGHT_HARD = 20 # Focus nhiá»u hÆ¡n vÃ o fraud

# Huáº¥n luyá»‡n vá»›i config tÃ¹y chá»‰nh
model = ADWCDFS(config=config, verbose=1)
model.fit(X_train, y_train)
```

### CÃ¡ch 3: Save vÃ  Load Model

```python
from adwc_dfs import ADWCDFS

# Train vÃ  save
model = ADWCDFS()
model.fit(X_train, y_train)
model.save('my_model.pkl')

# Load vÃ  sá»­ dá»¥ng
loaded_model = ADWCDFS.load('my_model.pkl')
predictions = loaded_model.predict_proba(X_new)
```

## ğŸ”§ TÃ¹y Chá»‰nh Hyperparameters

### Parameters Quan Trá»ng

**1. K_NEIGHBORS** (20-50)
- Máº·c Ä‘á»‹nh: 30
- Nhá» hÆ¡n (20): Nhanh hÆ¡n, local hÆ¡n
- Lá»›n hÆ¡n (50): Cháº­m hÆ¡n, global hÆ¡n

```python
config.K_NEIGHBORS = 40
```

**2. ALPHA, BETA, GAMMA** (tá»•ng â‰ˆ 1.0)
- ALPHA: Trá»ng sá»‘ cho CCDR (class overlap)
- BETA: Trá»ng sá»‘ cho LID (complexity)
- GAMMA: Trá»ng sá»‘ cho similarity

```python
config.ALPHA = 0.4
config.BETA = 0.3
config.GAMMA = 0.3
```

**3. SCALE_POS_WEIGHT** (1-20)
- Easy: 5 (máº·c Ä‘á»‹nh)
- Medium: 10 (máº·c Ä‘á»‹nh)
- Hard: 15 (máº·c Ä‘á»‹nh)
- TÄƒng náº¿u recall tháº¥p

```python
config.SCALE_POS_WEIGHT_EASY = 7
config.SCALE_POS_WEIGHT_MEDIUM = 12
config.SCALE_POS_WEIGHT_HARD = 18
```

## ğŸ“Š Hiá»ƒu Káº¿t Quáº£

### Metrics Quan Trá»ng

- **Precision**: Trong sá»‘ dá»± Ä‘oÃ¡n lÃ  fraud, bao nhiÃªu % tháº­t sá»± lÃ  fraud
- **Recall**: Trong sá»‘ fraud tháº­t, báº¯t Ä‘Æ°á»£c bao nhiÃªu %
- **F1 Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- **PR AUC**: Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong PR (tá»‘t cho imbalanced data)
- **ROC AUC**: Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC

### Performance Mong Äá»£i (10% data)

**Single Model:**
| Metric | GiÃ¡ Trá»‹ |
|--------|---------|
| Precision | ~0.69 |
| Recall | ~0.44 |
| F1 Score | ~0.54 |
| PR AUC | ~0.63 |
| ROC AUC | ~0.95 |

**Ensemble (5 models):** â­
| Strategy | Recall | Precision |
|----------|--------|-----------|
| Soft Voting | 88-90% | 16-18% |
| Aggressive (2/5) | 90-92% | 14-16% |
| Aggressive (1/5) | 92-95% | 12-14% |

**LÆ°u Ã½:** Káº¿t quáº£ tá»‘t hÆ¡n vá»›i nhiá»u dá»¯ liá»‡u hÆ¡n!

### Top Features ThÆ°á»ng Tháº¥y

1. **confidence_trajectory**: Thay Ä‘á»•i prediction tá»« easy Ä‘áº¿n hard
2. **mean_prediction**: Prediction trung bÃ¬nh
3. **entropy_pred**: Äá»™ báº¥t Ä‘á»“ng giá»¯a models
4. **DS**: Difficulty score
5. **LID**: Local dimensionality

## ğŸ›ï¸ Tuning Threshold

```python
# Thá»­ cÃ¡c threshold khÃ¡c nhau
for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:
    y_pred = model.predict(X_test, threshold=threshold)
    # ÄÃ¡nh giÃ¡...

# Threshold tháº¥p (0.3-0.4): Recall cao, nhiá»u false positive
# Threshold cao (0.6-0.7): Precision cao, nhiá»u false negative
# Máº·c Ä‘á»‹nh (0.5): CÃ¢n báº±ng
```

## ğŸ› Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p

### Lá»—i: Out of Memory

**NguyÃªn nhÃ¢n:** k-NN tá»‘n nhiá»u memory

**Giáº£i phÃ¡p:**
```bash
# Giáº£m K_NEIGHBORS
uv run train.py --k_neighbors 20

# Hoáº·c dÃ¹ng Ã­t data hÆ¡n
uv run train.py --sample_frac 0.05
```

### Lá»—i: Training QuÃ¡ Cháº­m

**Giáº£i phÃ¡p:**
```python
# Giáº£m Ä‘á»™ phá»©c táº¡p cascade models
config.CASCADE_PARAMS = {
    'n_estimators': 50,    # Giáº£m tá»« 100
    'max_depth': 5,        # Giáº£m tá»« 7
    ...
}
```

### Lá»—i: Performance KÃ©m

**Giáº£i phÃ¡p:**
```python
# TÄƒng focus vÃ o fraud
config.SCALE_POS_WEIGHT_HARD = 25

# TÄƒng sá»‘ neighbors
config.K_NEIGHBORS = 50

# Giáº£m threshold
y_pred = model.predict(X_test, threshold=0.3)
```

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### Cho NgÆ°á»i Má»›i Báº¯t Äáº§u:
1. Äá»c `QUICKSTART.md`
2. Cháº¡y `demo.py`
3. Thá»­ `train.py --sample_frac 0.1`
4. â­ Test ensemble: `python test_ensemble.py`

### Cho NgÆ°á»i CÃ³ Kinh Nghiá»‡m:
1. Äá»c `README.md`
2. Cháº¡y full training
3. â­ Train ensemble: `python ensemble_voting.py --n_models 5`
4. Äá»c `ENSEMBLE_USAGE_GUIDE.md` â­
5. So sÃ¡nh vá»›i baselines
6. Tune hyperparameters

### Cho ChuyÃªn Gia:
1. Äá»c `ALGORITHM.md`
2. Xem `example_usage.py`
3. â­ TÃ¹y chá»‰nh ensemble strategies
4. TÃ¹y chá»‰nh cÃ¡c stages
5. Má»Ÿ rá»™ng vá»›i domain features

## ğŸ’¡ Tips vÃ  Tricks

### 1. Data Preparation
```python
# LuÃ´n standardize features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

### 2. Monitoring Training
```python
# Báº­t verbose Ä‘á»ƒ theo dÃµi
model = ADWCDFS(verbose=1)
```

### 3. Feature Engineering
```python
# ThÃªm domain-specific features trÆ°á»›c khi train
# VD: transaction hour, day of week, amount bins, etc.
```

### 4. Threshold Selection
```python
# Chá»n threshold dá»±a trÃªn business requirement
# Cost cá»§a false positive vs false negative
if cost_FN > 10 * cost_FP:
    threshold = 0.3  # Æ¯u tiÃªn recall
else:
    threshold = 0.7  # Æ¯u tiÃªn precision
```

## ğŸ¯ Use Cases

### 1. Fraud Detection (PhÃ¡t hiá»‡n gian láº­n)
```python
# Credit card fraud, insurance fraud, etc.
model = ADWCDFS()
model.fit(X_transactions, y_is_fraud)
```

### 2. Anomaly Detection (PhÃ¡t hiá»‡n báº¥t thÆ°á»ng)
```python
# Network intrusion, system failures, etc.
config.K_NEIGHBORS = 50  # Cáº§n neighbors nhiá»u hÆ¡n
model = ADWCDFS(config=config)
```

### 3. Medical Diagnosis (Cháº©n Ä‘oÃ¡n y táº¿)
```python
# Rare disease detection
config.SCALE_POS_WEIGHT_HARD = 30  # Focus cao vÃ o positive
model = ADWCDFS(config=config)
```

## ğŸ“ Há»— Trá»£

Náº¿u gáº·p váº¥n Ä‘á»:
1. Check cÃ¡c file documentation
2. Xem example scripts
3. Äá»c code comments
4. Test vá»›i sample nhá» trÆ°á»›c

## ğŸ‰ Káº¿t Luáº­n

ADWC-DFS lÃ  thuáº­t toÃ¡n:
- âœ… **HoÃ n chá»‰nh** - Äáº§y Ä‘á»§ tÃ­nh nÄƒng
- âœ… **Dá»… sá»­ dá»¥ng** - API Ä‘Æ¡n giáº£n
- âœ… **Hiá»‡u quáº£** - Performance tá»‘t
- âœ… **Production-ready** - Sáºµn sÃ ng triá»ƒn khai

**Báº¯t Ä‘áº§u ngay:**
```bash
cd /home/shynn/source/ADWC-DFS
uv run demo.py
```

---

**ChÃºc báº¡n phÃ¡t hiá»‡n fraud thÃ nh cÃ´ng! ğŸ¯ğŸš€**
