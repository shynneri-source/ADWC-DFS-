# HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng ADWC-DFS (Tiáº¿ng Viá»‡t)

## ğŸ¯ Giá»›i Thiá»‡u

**ADWC-DFS** (Adaptive Density-Weighted Cascade with Dynamic Feature Synthesis) lÃ  má»™t thuáº­t toÃ¡n machine learning tiÃªn tiáº¿n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho bÃ i toÃ¡n **phÃ¡t hiá»‡n gian láº­n** vá»›i dá»¯ liá»‡u máº¥t cÃ¢n báº±ng.

### Äáº·c Ä‘iá»ƒm ná»•i báº­t:
- âœ… KhÃ´ng cáº§n resampling (SMOTE, oversampling)
- âœ… Nhanh vÃ  hiá»‡u quáº£ (O(nÂ·kÂ·d))
- âœ… Dá»… hiá»ƒu vÃ  giáº£i thÃ­ch Ä‘Æ°á»£c
- âœ… Sáºµn sÃ ng triá»ƒn khai production
- âœ… Ãt hyperparameter cáº§n tune

## ğŸ—ï¸ Kiáº¿n TrÃºc

Thuáº­t toÃ¡n gá»“m 4 giai Ä‘oáº¡n:

### Giai Ä‘oáº¡n 1: PhÃ¢n TÃ­ch Máº­t Äá»™ Cá»¥c Bá»™
TÃ­nh toÃ¡n Ä‘á»™ khÃ³ cho má»—i máº«u dá»±a trÃªn:
- **LID**: Äá»™ phá»©c táº¡p khÃ´ng gian cá»¥c bá»™
- **CCDR**: Tá»· lá»‡ máº­t Ä‘á»™ giá»¯a cÃ¡c class
- **DS**: Äiá»ƒm sá»‘ Ä‘á»™ khÃ³ tá»•ng há»£p

### Giai Ä‘oáº¡n 2: Huáº¥n Luyá»‡n Cascade
Ba mÃ´ hÃ¬nh chuyÃªn biá»‡t:
- **Easy Model**: Há»c cÃ¡c máº«u dá»…
- **Medium Model**: Há»c táº¥t cáº£ máº«u
- **Hard Model**: Táº­p trung vÃ o máº«u khÃ³

### Giai Ä‘oáº¡n 3: Tá»•ng Há»£p Äáº·c TrÆ°ng Äá»™ng
Táº¡o meta-features tá»«:
- Sá»± báº¥t Ä‘á»“ng giá»¯a cÃ¡c models
- Äá»™ tin cáº­y cá»§a predictions
- Äá»“ng thuáº­n tá»« neighbors

### Giai Ä‘oáº¡n 4: Meta-Classifier
MÃ´ hÃ¬nh cuá»‘i cÃ¹ng vá»›i:
- Adaptive weighting
- Uncertainty-based learning

## ğŸ“¦ CÃ i Äáº·t

```bash
## ğŸš€ Báº¯t Äáº§u Ngay!

```bash
# 1. VÃ o thÆ° má»¥c
cd /home/shyn/Dev/ADWC-DFS-

# 2. Test ensemble nhanh
python test_ensemble.py

# 3. Train production
python ensemble_voting.py --n_models 5

# 4. Enjoy! ğŸ‰
```
```

## ğŸš€ Sá»­ Dá»¥ng Nhanh

## ğŸ¯ Next Steps for Users

### Beginner:
1. Read `START_HERE.md`
2. Run `python test_ensemble.py`
3. Try full training: `python ensemble_voting.py --n_models 5`
4. â­ Monitor training: `bash monitor_training.sh`

**ğŸ“š Xem chi tiáº¿t:** [ENSEMBLE_USAGE_GUIDE.md](ENSEMBLE_USAGE_GUIDE.md)

### 3. So SÃ¡nh Vá»›i Baselines

```bash
uv run evaluate.py --sample_frac 0.1 --output_csv results/comparison.csv
# ğŸ“ Log: logs/evaluation_YYYYMMDD_HHMMSS.log
```

So sÃ¡nh vá»›i:
- XGBoost vá»›i class weights
- SMOTE + XGBoost  
- Random Forest
- ADWC-DFS

## ğŸ“ Xem Training Logs

**Táº¥t cáº£ training tá»± Ä‘á»™ng lÆ°u log!**

```bash
# Liá»‡t kÃª táº¥t cáº£ logs
uv run view_logs.py --list

# Xem log má»›i nháº¥t
uv run view_logs.py --latest

# Xem log cá»¥ thá»ƒ (sá»‘ thá»© tá»± tá»« list)
uv run view_logs.py --view 1

# TÃ¬m kiáº¿m trong logs
uv run view_logs.py --search "F1 Score"

# Xem 100 dÃ²ng cuá»‘i
uv run view_logs.py --latest --lines 100 --tail

# Chá»‰ xem training logs
uv run view_logs.py --list --prefix training
```

**Log files:** `logs/training_YYYYMMDD_HHMMSS.log`

**Xem chi tiáº¿t:** [LOGGING_GUIDE.md](LOGGING_GUIDE.md) - HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ vá» logging

## ğŸ’» Sá»­ Dá»¥ng Trong Code

### CÃ¡ch 1: CÆ¡ Báº£n (Single Model)

```python
from adwc_dfs import ADWCDFS

# Khá»Ÿi táº¡o model vá»›i config máº·c Ä‘á»‹nh
model = ADWCDFS(verbose=1)

# Huáº¥n luyá»‡n
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred_proba = model.predict_proba(X_test)
y_pred = model.predict(X_test, threshold=0.5)

# Feature importance
importance = model.get_feature_importance()
print(importance.head(10))
```

### CÃ¡ch 1.5: Ensemble (Recall cao hÆ¡n) â­

```python
from ensemble_voting import VotingEnsemble

# Táº¡o ensemble vá»›i 5 models
ensemble = VotingEnsemble(n_models=5, voting='soft', verbose=1)

# Huáº¥n luyá»‡n
ensemble.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n vá»›i soft voting (cÃ¢n báº±ng)
y_pred = ensemble.predict(X_test, threshold=0.13)

# Hoáº·c aggressive voting (maximize recall)
y_pred = ensemble.predict_aggressive(X_test, min_votes=2)

# Save ensemble
ensemble.save('results/ensemble_model.pkl')

# Load vÃ  sá»­ dá»¥ng
loaded = VotingEnsemble.load('results/ensemble_model.pkl')
```

### CÃ¡ch 2: TÃ¹y Chá»‰nh Config

```python
from adwc_dfs import ADWCDFS
from adwc_dfs.config import ADWCDFSConfig

# Táº¡o config tÃ¹y chá»‰nh
config = ADWCDFSConfig()
config.K_NEIGHBORS = 50           # TÄƒng sá»‘ neighbors
config.ALPHA = 0.5                # TÄƒng trá»ng sá»‘ CCDR
config.SCALE_POS_WEIGHT_HARD = 20 # Focus nhiá»u hÆ¡n vÃ o fraud

# Huáº¥n luyá»‡n vá»›i config tÃ¹y chá»‰nh
model = ADWCDFS(config=config, verbose=1)
model.fit(X_train, y_train)
```

### CÃ¡ch 3: Save vÃ  Load Model

```python
from adwc_dfs import ADWCDFS

# Train vÃ  save
model = ADWCDFS()
model.fit(X_train, y_train)
model.save('my_model.pkl')

# Load vÃ  sá»­ dá»¥ng
loaded_model = ADWCDFS.load('my_model.pkl')
predictions = loaded_model.predict_proba(X_new)
```

## ğŸ”§ TÃ¹y Chá»‰nh Hyperparameters

### File: `adwc_dfs/config.py`

```python
# Stage 1: Density Profiling
k_neighbors = 30  # Sá»‘ lÆ°á»£ng neighbors Ä‘á»ƒ tÃ­nh LID/CCDR

# Stage 2: Cascade Training
scale_pos_weight_easy = 40.0    # Weight cho fraud class - easy model
scale_pos_weight_medium = 60.0  # Weight cho fraud class - medium model
scale_pos_weight_hard = 80.0    # Weight cho fraud class - hard model

# Stage 4: Meta-Classifier
alpha = 10.0  # Weight cho hard+uncertain samples
```

### Thá»­ Nghiá»‡m
```bash
# Test vá»›i sample nhá»
python ensemble_voting.py --n_models 3 --sample_frac 0.05

# Train vá»›i nhiá»u models hÆ¡n
python ensemble_voting.py --n_models 7
```

## ğŸ“Š Hiá»ƒu Káº¿t Quáº£

### Metrics Quan Trá»ng

- **Precision**: Trong sá»‘ dá»± Ä‘oÃ¡n lÃ  fraud, bao nhiÃªu % tháº­t sá»± lÃ  fraud
- **Recall**: Trong sá»‘ fraud tháº­t, báº¯t Ä‘Æ°á»£c bao nhiÃªu %
- **F1 Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- **PR AUC**: Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong PR (tá»‘t cho imbalanced data)
- **ROC AUC**: Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC

### Performance Mong Äá»£i (10% data)

**Single Model:**
| Metric | GiÃ¡ Trá»‹ |
|--------|---------|
| Precision | ~0.69 |
| Recall | ~0.44 |
| F1 Score | ~0.54 |
| PR AUC | ~0.63 |
| ROC AUC | ~0.95 |

**Ensemble (5 models):** â­
| Strategy | Recall | Precision |
|----------|--------|-----------|
| Soft Voting (0.13) | 83.9% | 25.4% |
| Soft Voting (0.10) | 85.8% | 21.2% |
| Aggressive (2/5) | 88.3% | 17.7% |
| Aggressive (1/5) | 90.2% | 14.5% |
| ULTRA AGGRESSIVE | 91.4% | 13.0% |

**LÆ°u Ã½:** Káº¿t quáº£ tá»‘t hÆ¡n vá»›i nhiá»u dá»¯ liá»‡u hÆ¡n!

### Top Features ThÆ°á»ng Tháº¥y

1. **confidence_trajectory**: Thay Ä‘á»•i prediction tá»« easy Ä‘áº¿n hard
2. **mean_prediction**: Prediction trung bÃ¬nh
3. **entropy_pred**: Äá»™ báº¥t Ä‘á»“ng giá»¯a models
4. **DS**: Difficulty score
5. **LID**: Local dimensionality

## ğŸ›ï¸ Tuning Threshold

```python
# Thá»­ cÃ¡c threshold khÃ¡c nhau
for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:
    y_pred = model.predict(X_test, threshold=threshold)
    # ÄÃ¡nh giÃ¡...

# Threshold tháº¥p (0.3-0.4): Recall cao, nhiá»u false positive
# Threshold cao (0.6-0.7): Precision cao, nhiá»u false negative
# Máº·c Ä‘á»‹nh (0.5): CÃ¢n báº±ng
```

## ğŸ› Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p

### Lá»—i: Out of Memory

**NguyÃªn nhÃ¢n:** k-NN tá»‘n nhiá»u memory

**Giáº£i phÃ¡p:**
```bash
# Giáº£m K_NEIGHBORS
uv run train.py --k_neighbors 20

# Hoáº·c dÃ¹ng Ã­t data hÆ¡n
uv run train.py --sample_frac 0.05
```

### Lá»—i: Training QuÃ¡ Cháº­m

**Giáº£i phÃ¡p:**
```python
# Giáº£m Ä‘á»™ phá»©c táº¡p cascade models
config.CASCADE_PARAMS = {
    'n_estimators': 50,    # Giáº£m tá»« 100
    'max_depth': 5,        # Giáº£m tá»« 7
    ...
}
```

### Lá»—i: Performance KÃ©m

**Giáº£i phÃ¡p:**
```python
# TÄƒng focus vÃ o fraud
config.SCALE_POS_WEIGHT_HARD = 25

# TÄƒng sá»‘ neighbors
config.K_NEIGHBORS = 50

# Giáº£m threshold
y_pred = model.predict(X_test, threshold=0.3)
```

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### Cho NgÆ°á»i Má»›i Báº¯t Äáº§u:
1. Äá»c `START_HERE.md`
2. Cháº¡y `python test_ensemble.py`
3. Thá»­ full training: `python ensemble_voting.py --n_models 5`
4. â­ Monitor: `bash monitor_training.sh`

### Cho NgÆ°á»i CÃ³ Kinh Nghiá»‡m:
1. Äá»c `README.md`
2. Cháº¡y full training
3. â­ Train ensemble: `python ensemble_voting.py --n_models 5`
4. Äá»c `ENSEMBLE_USAGE_GUIDE.md` â­
5. So sÃ¡nh vá»›i baselines
6. Tune hyperparameters

### Cho ChuyÃªn Gia:
1. Äá»c `ALGORITHM.md`
2. TÃ¹y chá»‰nh `ensemble_voting.py`
3. â­ Implement custom voting strategies
4. TÃ¹y chá»‰nh cÃ¡c stages
5. Má»Ÿ rá»™ng vá»›i domain features

## ğŸ’¡ Tips vÃ  Tricks

### 1. Data Preparation
```python
# LuÃ´n standardize features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

### 2. Monitoring Training
```python
# Báº­t verbose Ä‘á»ƒ theo dÃµi
model = ADWCDFS(verbose=1)
```

### 3. Feature Engineering
```python
# ThÃªm domain-specific features trÆ°á»›c khi train
# VD: transaction hour, day of week, amount bins, etc.
```

### 4. Threshold Selection
```python
# Chá»n threshold dá»±a trÃªn business requirement
# Cost cá»§a false positive vs false negative
if cost_FN > 10 * cost_FP:
    threshold = 0.3  # Æ¯u tiÃªn recall
else:
    threshold = 0.7  # Æ¯u tiÃªn precision
```

## ğŸ¯ Use Cases

### 1. Fraud Detection (PhÃ¡t hiá»‡n gian láº­n)
```python
# Credit card fraud, insurance fraud, etc.
model = ADWCDFS()
model.fit(X_transactions, y_is_fraud)
```

### 2. Anomaly Detection (PhÃ¡t hiá»‡n báº¥t thÆ°á»ng)
```python
# Network intrusion, system failures, etc.
config.K_NEIGHBORS = 50  # Cáº§n neighbors nhiá»u hÆ¡n
model = ADWCDFS(config=config)
```

### 3. Medical Diagnosis (Cháº©n Ä‘oÃ¡n y táº¿)
```python
# Rare disease detection
config.SCALE_POS_WEIGHT_HARD = 30  # Focus cao vÃ o positive
model = ADWCDFS(config=config)
```

## ğŸ“ Há»— Trá»£

Náº¿u gáº·p váº¥n Ä‘á»:
1. Check cÃ¡c file documentation
2. Xem example scripts
3. Äá»c code comments
4. Test vá»›i sample nhá» trÆ°á»›c

## ğŸ‰ Káº¿t Luáº­n

ADWC-DFS lÃ  thuáº­t toÃ¡n:
- âœ… **HoÃ n chá»‰nh** - Äáº§y Ä‘á»§ tÃ­nh nÄƒng
- âœ… **Dá»… sá»­ dá»¥ng** - API Ä‘Æ¡n giáº£n
- âœ… **Hiá»‡u quáº£** - Performance tá»‘t
- âœ… **Production-ready** - Sáºµn sÃ ng triá»ƒn khai

**Báº¯t Ä‘áº§u ngay:**
```bash
cd /home/shynn/source/ADWC-DFS
uv run demo.py
```

---

**ChÃºc báº¡n phÃ¡t hiá»‡n fraud thÃ nh cÃ´ng! ğŸ¯ğŸš€**
